{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reference genome...\n",
      "Loading paired reads...\n",
      "Building k-mer index...\n",
      "Calling substitutions...\n",
      "Found 150 substitution candidates.\n",
      "Predictions saved to predicted_mutations_project1a.txt.\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from collections import defaultdict, Counter\n",
    "import sys\n",
    "\n",
    "# Load Reference Genome \n",
    "def load_reference_genome(file_path):\n",
    "    for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "        return str(record.seq)\n",
    "\n",
    "# Load Paired Reads\n",
    "def load_paired_reads(file_path):\n",
    "    paired_reads = []\n",
    "    current_pair = {}\n",
    "\n",
    "    for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "        read_id = record.id\n",
    "        sequence = str(record.seq)\n",
    "\n",
    "        if read_id.endswith(\"/1\"):\n",
    "            read_num = 1\n",
    "        elif read_id.endswith(\"/2\"):\n",
    "            read_num = 2\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        base_id = read_id.rsplit(\"/\", 1)[0]\n",
    "\n",
    "        if base_id not in current_pair:\n",
    "            current_pair[base_id] = {}\n",
    "\n",
    "        current_pair[base_id][read_num] = sequence\n",
    "\n",
    "        if 1 in current_pair[base_id] and 2 in current_pair[base_id]:\n",
    "            paired_reads.append((current_pair[base_id][1], current_pair[base_id][2]))\n",
    "            del current_pair[base_id]\n",
    "\n",
    "    return paired_reads\n",
    "\n",
    "# K-mer Indexing\n",
    "def build_kmer_index(reference, k=15):\n",
    "    index = defaultdict(list)\n",
    "    for i in range(len(reference) - k + 1):\n",
    "        kmer = reference[i:i + k]\n",
    "        index[kmer].append(i)\n",
    "    return index\n",
    "\n",
    "# Align Read to Reference with Hamming Distance\n",
    "def hamming_distance(s1, s2):\n",
    "    if len(s1) != len(s2): return sys.maxsize\n",
    "    return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n",
    "\n",
    "def map_read_to_reference(read, reference, kmer_index, k=15, max_mismatches=5):\n",
    "    best_pos = None\n",
    "    best_score = sys.maxsize\n",
    "\n",
    "    for i in range(len(read) - k + 1):\n",
    "        kmer = read[i:i + k]\n",
    "        if kmer in kmer_index:\n",
    "            for ref_pos in kmer_index[kmer]:\n",
    "                start = ref_pos - i\n",
    "                end = start + len(read)\n",
    "                if start < 0 or end > len(reference): continue\n",
    "                ref_sub = reference[start:end]\n",
    "                dist = hamming_distance(read, ref_sub)\n",
    "                if dist < best_score and dist <= max_mismatches:\n",
    "                    best_score = dist\n",
    "                    best_pos = start\n",
    "    return best_pos\n",
    "\n",
    "# Step 5: Call Substitutions \n",
    "def call_substitutions(reference, paired_reads, kmer_index, k=15):\n",
    "    sub_counts = defaultdict(Counter)\n",
    "\n",
    "    for read1, read2 in paired_reads:\n",
    "        for read in [read1, read2]:\n",
    "            pos = map_read_to_reference(read, reference, kmer_index, k)\n",
    "            if pos is None: continue\n",
    "            for i, base in enumerate(read):\n",
    "                ref_index = pos + i\n",
    "                if ref_index < len(reference):\n",
    "                    ref_base = reference[ref_index]\n",
    "                    if base != ref_base:\n",
    "                        sub_counts[ref_index][base] += 1\n",
    "\n",
    "    # Filter with minimum read support threshold\n",
    "    predictions = []\n",
    "    for pos, counter in sub_counts.items():\n",
    "        total = sum(counter.values())\n",
    "        base, count = counter.most_common(1)[0]\n",
    "        if count >= 3:  # threshold: at least 3 reads support the variant\n",
    "            predictions.append((pos, reference[pos], base))\n",
    "\n",
    "    return sorted(predictions, key=lambda x: x[0])\n",
    "\n",
    "# Step 6: Save Substitutions to File\n",
    "def save_predictions(predictions, output_file):\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for pos, ref_base, alt_base in predictions:\n",
    "            f.write(f\">S{pos} {ref_base} {alt_base}\\n\")\n",
    "\n",
    "# ---- Step 7: Main Pipeline ---- #\n",
    "def main():\n",
    "    ref_file = \"project1a_reference_genome.fasta\"\n",
    "    reads_file = \"project1a_with_error_paired_reads.fasta\"\n",
    "    output_file = \"predicted_mutations_project1a.txt\"\n",
    "\n",
    "    print(\"Loading reference genome...\")\n",
    "    reference = load_reference_genome(ref_file)\n",
    "\n",
    "    print(\"Loading paired reads...\")\n",
    "    paired_reads = load_paired_reads(reads_file)\n",
    "\n",
    "    print(\"Building k-mer index...\")\n",
    "    kmer_index = build_kmer_index(reference, k=15)\n",
    "\n",
    "    print(\"Calling substitutions...\")\n",
    "    substitutions = call_substitutions(reference, paired_reads, kmer_index, k=15)\n",
    "\n",
    "    print(f\"Found {len(substitutions)} substitution candidates.\")\n",
    "    save_predictions(substitutions, output_file)\n",
    "    print(f\"Predictions saved to {output_file}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
